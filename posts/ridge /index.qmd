---
title: "Ridge Regression"
author: ""
date: "2023-02-14"
categories: [R, code, Ridge Regression]
---

## R code to estimated a Ridge regression

In this example, we first generate some sample data with **`n`** observations and **`p`** predictor variables. We then define the **`lambda`** value for the ridge regression.

The **`solve()`** function is used to solve the normal equation for ridge regression. We add **`lambda * diag(p)`** to the **`t(X) %*% X`** term, which is equivalent to adding the ridge penalty term to the least squares regression.

Finally, we multiply the result by **`t(X) %*% y`** to get the ridge regression coefficients. The resulting coefficients are stored in the **`ridge_coef`** variable, which we print to the console.

```{r}
# Generate sample data
set.seed(123)
n <- 100
p <- 10
X <- matrix(rnorm(n*p), nrow=n)
y <- rnorm(n)

# Define lambda value
lambda <- 0.5

# Calculate ridge regression coefficients
ridge_coef <- solve(t(X) %*% X + lambda * diag(p)) %*% t(X) %*% y

# Print coefficients
ridge_coef

```

## R code to estimated a Ridge regression using Maximum Likelihood

In this example, we first generate some sample data with **`n`** observations and **`p`** predictor variables. We then define the **`lambda`** value for the ridge regression.

Next, we define the **`ridge_fun`** function to optimize. This function takes as input the **`beta`** vector of regression coefficients, the predictor matrix **`X`**, the response vector **`y`**, and the **`lambda`** value. It returns the sum of the residual sum of squares and the ridge penalty term.

We then use the **`optim`** function to find the optimal value of **`beta`** that minimizes the **`ridge_fun`** function. The starting values for **`beta`** are set to zero with **`rep(0,p)`**. The other inputs to **`optim`** are the **`ridge_fun`** function, **`X`**, **`y`**, and **`lambda`**. The **`par`** element of the output from **`optim`** contains the estimated coefficients.

Finally, we print the estimated coefficients to the console.

```{r}
# Generate sample data
set.seed(123)
n <- 100
p <- 10
X <- matrix(rnorm(n*p), nrow=n)
y <- rnorm(n)

# Define lambda value
lambda <- 0.5

# Define function to optimize
ridge_fun <- function(beta, X, y, lambda) {
  sum((y - X %*% beta)^2) + lambda * sum(beta^2)
}

# Use optim to find the ridge regression coefficients
ridge_coef <- optim(par=rep(0,p), fn=ridge_fun, X=X, y=y, lambda=lambda)$par

# Print coefficients
ridge_coef

```
